{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01e7f00a-b3ff-4f89-8fb2-26750053bd3c",
   "metadata": {},
   "source": [
    "The client provided four raw datasets: (1) the curriculum/knowledge framework (Skills and Knowledge years 3–10.json), (2) a STEM careers requirement catalog (STEM Careers.json), (3) sample student profiles (mock_users_progress.json), and (4) a field glossary (json_schema_documentation.md). Key issues included inconsistent schemas across files (id vs user_id, knowledge vs knowledge_progress, uneven level naming), mismatches between career requirements and knowledge node IDs, missing or non-standard thresholds/weights/difficulties, user profiles with near-zero signals (everyone appears “cold start”), and no production-ready learning content library to feed recommendations. To ensure usability and explainability, we performed data preprocessing: unified node IDs and level semantics (L1/L2/L3) and built a searchable skills index; normalized the careers file to id/title/min_skill_levels/required_knowledge[{node,min_level,weight}]/threshold; standardized student profiles to id/grade/inquiry_skills/knowledge with robust type/blank handling; and, lacking real content, generated a placeholder learning content library (one unit per “knowledge node × level”) to enable end-to-end testing. After preprocessing we obtained four engine-ready artifacts—skills_index.json, careers_normalized.json, users_normalized.json, and units_placeholder.json—with aligned schemas, complete fields, and traceable, interpretable mappings suitable for the current rules-based recommendation engine and frontend integration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e21034-694c-4422-9fd9-e8de45da52f3",
   "metadata": {},
   "source": [
    "Step 1 — Curriculum / Knowledge base (Skills and Knowledge years 3–10.json)\n",
    "\n",
    "What\n",
    "Normalize the curriculum file into a flat, searchable index of knowledge nodes, unify the levels structure, and (optionally) auto-generate placeholder learning units so recommendations can already produce “next actions”.\n",
    "\n",
    "Why\n",
    "\n",
    "The raw levels field appears as both arrays and objects; inconsistent shapes make parsing brittle.\n",
    "\n",
    "The recommender needs fast lookups by node id, hence a flat index.\n",
    "\n",
    "Before you have real content, “node × level” placeholders keep the UX loop complete.\n",
    "\n",
    "How\n",
    "\n",
    "Recursively walk the JSON; collect id/title/subject/grade/levels for every node.\n",
    "\n",
    "Normalize levels to a single shape: {1:{…}, 2:{…}, …} preserving description/outcomes.\n",
    "\n",
    "Extract progression_to (if present) into directed edges.\n",
    "\n",
    "Generate placeholders: one unit per node × level (difficulty≈level, default lengthMin, pointing back to that node).\n",
    "\n",
    "Output\n",
    "\n",
    "skills_index.json — flat index: id → {title, subject, grade, levels{1:{…}}}\n",
    "\n",
    "skills_edges.json — [{\"from\",\"to\"}] progression edges (may be empty)\n",
    "\n",
    "units_placeholder.json — optional placeholder content (node × level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f439d8-73f2-4cec-b71c-72b7933bb2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 输出完成\n",
      "  节点数: 33\n",
      "  level 条目数: 99\n",
      "  进阶边数: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>subject</th>\n",
       "      <th>grade</th>\n",
       "      <th>levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIO.Y3.AC9S3U01</td>\n",
       "      <td>Living vs non-living; life cycles (intro)</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EARTH.Y3.AC9S3U02</td>\n",
       "      <td>Soils, rocks, minerals (properties &amp; resources)</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PHYS.Y3.AC9S3U03</td>\n",
       "      <td>Heat sources &amp; temperature change</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHEM.Y3.AC9S3U04</td>\n",
       "      <td>Solids &amp; liquids; changes of state</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIO.Y4.AC9S4U01</td>\n",
       "      <td>Life cycles (development &amp; variation)</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BIO.Y4.AC9S4U02</td>\n",
       "      <td>Interdependence &amp; environments</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EARTH.Y4.AC9S4U03</td>\n",
       "      <td>Earth’s surface changes</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CHEM.Y4.AC9S4U04</td>\n",
       "      <td>Material properties &amp; uses</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PHYS.Y4.AC9S4U05</td>\n",
       "      <td>Forces: contact &amp; non-contact</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BIO.Y5.AC9S5U01</td>\n",
       "      <td>Adaptations for survival</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EARTH.Y5.AC9S5U02</td>\n",
       "      <td>Earth surface processes</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PHYS.Y5.AC9S5U03</td>\n",
       "      <td>Light, shadows, reflection &amp; refraction</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CHEM.Y5.AC9S5U04</td>\n",
       "      <td>Particle model: solids, liquids, gases</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BIO.Y6.AC9S6U01</td>\n",
       "      <td>Habitats &amp; survival conditions</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EARTH.Y6.AC9S6U02</td>\n",
       "      <td>Sun–Earth–planet relationships</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PHYS.Y6.AC9S6U03</td>\n",
       "      <td>Electrical circuits &amp; components</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CHEM.Y6.AC9S6U04</td>\n",
       "      <td>Reversible vs irreversible changes</td>\n",
       "      <td>None</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BIO.Y7.AC9S7U01</td>\n",
       "      <td>Environmental factors and survival</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EARTH.Y7.AC9S7U02</td>\n",
       "      <td>Sun–Earth–Moon phenomena</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PHYS.Y7.AC9S7U03</td>\n",
       "      <td>Forces (incl. friction &amp; gravity)</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                            title  \\\n",
       "0     BIO.Y3.AC9S3U01        Living vs non-living; life cycles (intro)   \n",
       "1   EARTH.Y3.AC9S3U02  Soils, rocks, minerals (properties & resources)   \n",
       "2    PHYS.Y3.AC9S3U03                Heat sources & temperature change   \n",
       "3    CHEM.Y3.AC9S3U04               Solids & liquids; changes of state   \n",
       "4     BIO.Y4.AC9S4U01            Life cycles (development & variation)   \n",
       "5     BIO.Y4.AC9S4U02                   Interdependence & environments   \n",
       "6   EARTH.Y4.AC9S4U03                          Earth’s surface changes   \n",
       "7    CHEM.Y4.AC9S4U04                       Material properties & uses   \n",
       "8    PHYS.Y4.AC9S4U05                    Forces: contact & non-contact   \n",
       "9     BIO.Y5.AC9S5U01                         Adaptations for survival   \n",
       "10  EARTH.Y5.AC9S5U02                          Earth surface processes   \n",
       "11   PHYS.Y5.AC9S5U03          Light, shadows, reflection & refraction   \n",
       "12   CHEM.Y5.AC9S5U04           Particle model: solids, liquids, gases   \n",
       "13    BIO.Y6.AC9S6U01                   Habitats & survival conditions   \n",
       "14  EARTH.Y6.AC9S6U02                   Sun–Earth–planet relationships   \n",
       "15   PHYS.Y6.AC9S6U03                 Electrical circuits & components   \n",
       "16   CHEM.Y6.AC9S6U04               Reversible vs irreversible changes   \n",
       "17    BIO.Y7.AC9S7U01               Environmental factors and survival   \n",
       "18  EARTH.Y7.AC9S7U02                         Sun–Earth–Moon phenomena   \n",
       "19   PHYS.Y7.AC9S7U03                Forces (incl. friction & gravity)   \n",
       "\n",
       "   subject  grade  levels  \n",
       "0     None      3       3  \n",
       "1     None      3       3  \n",
       "2     None      3       3  \n",
       "3     None      3       3  \n",
       "4     None      4       3  \n",
       "5     None      4       3  \n",
       "6     None      4       3  \n",
       "7     None      4       3  \n",
       "8     None      4       3  \n",
       "9     None      5       3  \n",
       "10    None      5       3  \n",
       "11    None      5       3  \n",
       "12    None      5       3  \n",
       "13    None      6       3  \n",
       "14    None      6       3  \n",
       "15    None      6       3  \n",
       "16    None      6       3  \n",
       "17    None      7       3  \n",
       "18    None      7       3  \n",
       "19    None      7       3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1 — 处理“Skills and Knowledge years 3-10.json”\n",
    "# 产出：skills_index.json, skills_edges.json, units_placeholder.json\n",
    "\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path.cwd()  # notebook dir\n",
    "SRC  = BASE / \"Skills and Knowledge years 3-10.json\"\n",
    "assert SRC.exists(), f\"not found：{SRC}\"\n",
    "\n",
    "with SRC.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    curriculum = json.load(f)\n",
    "\n",
    "def normalize_levels(levels_obj):\n",
    "    \"\"\"统一 levels 为 {1:{description, outcomes[]}, 2:{...}}\"\"\"\n",
    "    norm = {}\n",
    "    if isinstance(levels_obj, list):\n",
    "        for i, item in enumerate(levels_obj, start=1):\n",
    "            if isinstance(item, dict):\n",
    "                outs = item.get(\"outcomes\")\n",
    "                norm[i] = {\n",
    "                    \"description\": item.get(\"description\"),\n",
    "                    \"outcomes\": outs if isinstance(outs, list) else ([outs] if outs else []),\n",
    "                }\n",
    "            else:\n",
    "                norm[i] = {\"description\": str(item), \"outcomes\": []}\n",
    "    elif isinstance(levels_obj, dict):\n",
    "        tmp = []\n",
    "        for k, v in levels_obj.items():\n",
    "            m = re.search(r\"(\\d+)\", str(k))\n",
    "            if m: tmp.append((int(m.group(1)), v))\n",
    "        for n, item in sorted(tmp, key=lambda x: x[0]):\n",
    "            if isinstance(item, dict):\n",
    "                outs = item.get(\"outcomes\")\n",
    "                norm[n] = {\n",
    "                    \"description\": item.get(\"description\"),\n",
    "                    \"outcomes\": outs if isinstance(outs, list) else ([outs] if outs else []),\n",
    "                }\n",
    "            else:\n",
    "                norm[n] = {\"description\": str(item), \"outcomes\": []}\n",
    "    return norm\n",
    "\n",
    "# Collect nodes and edges\n",
    "skills_index = {}      # id -> {title, subject, grade, levels{1:{...}}}\n",
    "edges = []             # [{from, to}]\n",
    "\n",
    "def walk(obj, parent_subject=None, parent_grade=None):\n",
    "    if isinstance(obj, dict):\n",
    "        subject = obj.get(\"subject\") or parent_subject\n",
    "        grade   = obj.get(\"year\") or obj.get(\"grade\") or parent_grade\n",
    "\n",
    "        node_id = obj.get(\"id\")\n",
    "        title   = obj.get(\"title\")\n",
    "        if isinstance(node_id, str) and isinstance(title, str):\n",
    "            skills_index[node_id] = {\n",
    "                \"title\": title,\n",
    "                \"subject\": subject,\n",
    "                \"grade\": grade,\n",
    "                \"levels\": normalize_levels(obj.get(\"levels\")),\n",
    "            }\n",
    "            prog = obj.get(\"progression_to\", [])\n",
    "            if isinstance(prog, list):\n",
    "                for t in prog:\n",
    "                    if isinstance(t, str):\n",
    "                        edges.append({\"from\": node_id, \"to\": t})\n",
    "\n",
    "        for v in obj.values():\n",
    "            walk(v, subject, grade)\n",
    "    elif isinstance(obj, list):\n",
    "        for x in obj:\n",
    "            walk(x, parent_subject, parent_grade)\n",
    "\n",
    "walk(curriculum)\n",
    "\n",
    "# 生成占位学习单元（node × level）\n",
    "units_placeholder = []\n",
    "for nid, info in skills_index.items():\n",
    "    title = info[\"title\"]\n",
    "    for lvl in sorted(info[\"levels\"].keys()):\n",
    "        lvl_obj = info[\"levels\"][lvl]\n",
    "        units_placeholder.append({\n",
    "            \"id\": f\"{nid}::L{lvl}\",\n",
    "            \"title\": f\"提升「{title}」到 L{lvl}\",\n",
    "            \"kind\": \"practice\",\n",
    "            \"difficulty\": min(max(int(lvl),1),3),\n",
    "            \"lengthMin\": 8 if lvl == 1 else (10 if lvl == 2 else 12),\n",
    "            \"knowledge_nodes\": [{\"id\": nid, \"weight\": 1.0}],\n",
    "            \"skills\": [],\n",
    "            \"source\": \"placeholder-from-curriculum\",\n",
    "            \"license\": \"internal\",\n",
    "            \"steps\": (lvl_obj.get(\"outcomes\") or [])[:5]\n",
    "        })\n",
    "\n",
    "# write doc\n",
    "( BASE / \"skills_index.json\"   ).write_text(json.dumps(skills_index,   ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "( BASE / \"skills_edges.json\"   ).write_text(json.dumps(edges,          ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "( BASE / \"units_placeholder.json\").write_text(json.dumps(units_placeholder, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "print(\"✅ print finish\")\n",
    "print(\"  node num:\", len(skills_index))\n",
    "print(\"  level num:\", sum(len(v[\"levels\"]) for v in skills_index.values()))\n",
    "print(\"  Advanced edge count:\", len(edges))\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame([\n",
    "        {\"id\": nid, \"title\": info[\"title\"], \"subject\": info.get(\"subject\"), \"grade\": info.get(\"grade\"), \"levels\": len(info[\"levels\"])}\n",
    "        for nid, info in list(skills_index.items())[:20]\n",
    "    ])\n",
    "    display(df)\n",
    "except Exception as e:\n",
    "    sample = list(skills_index.items())[:3]\n",
    "    print(\"预览（前3条）：\")\n",
    "    for nid, info in sample:\n",
    "        print(\"-\", nid, \"=>\", info[\"title\"], \"| levels:\", list(info[\"levels\"].keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e42aae0-a51a-41f5-8609-84ee1c38ab09",
   "metadata": {},
   "source": [
    "Step 2 — Careers (STEM Careers.json)\n",
    "\n",
    "What\n",
    "Standardize knowledge node IDs in the careers file to match the curriculum, deduplicate/merge repeated required_knowledge entries, and validate references against the curriculum index.\n",
    "\n",
    "Why\n",
    "\n",
    "Careers use long prefixes (BIOLOGICAL/PHYSICAL/CHEMICAL) while the curriculum uses short ones (BIO/PHYS/CHEM); without normalization you’ll miss joins.\n",
    "\n",
    "The same node may appear multiple times; without merging you’ll double count weights.\n",
    "\n",
    "Early reference checks prevent runtime errors and highlight data gaps.\n",
    "\n",
    "How\n",
    "\n",
    "Apply a fixed prefix map: BIOLOGICAL→BIO, PHYSICAL→PHYS, CHEMICAL→CHEM, EARTH→EARTH.\n",
    "\n",
    "For each career’s required_knowledge: group by node, max the min_level, sum the weight.\n",
    "\n",
    "Compare the normalized node IDs against skills_index.json keys and list any missing references.\n",
    "\n",
    "Keep the original structure; only the normalized/merged required_knowledge changes.\n",
    "\n",
    "Output\n",
    "\n",
    "careers_normalized.json — careers with normalized node IDs and merged duplicates\n",
    "\n",
    "careers_validation_report.md — stats (merged counts, missing references detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ed1367-70ac-4dec-83a8-99f4e31611ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 输出完成： careers_normalized.json 和 careers_validation_report.md\n"
     ]
    }
   ],
   "source": [
    "# Step 2 — 处理 STEM Careers.json：前缀规范化 / 去重合并 / 引用校验\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path.cwd()\n",
    "SRC_CAREERS = BASE / \"STEM Careers.json\"\n",
    "SRC_SKILLS  = BASE / \"skills_index.json\"               #from step 1\n",
    "SRC_CURR    = BASE / \"Skills and Knowledge years 3-10.json\"  \n",
    "\n",
    "OUT_CAREERS = BASE / \"careers_normalized.json\"\n",
    "OUT_REPORT  = BASE / \"careers_validation_report.md\"\n",
    "\n",
    "assert SRC_CAREERS.exists(), f\"未找到 {SRC_CAREERS}\"\n",
    "\n",
    "def normalize_levels(levels_obj):\n",
    "    norm = {}\n",
    "    if isinstance(levels_obj, list):\n",
    "        for i, item in enumerate(levels_obj, start=1):\n",
    "            if isinstance(item, dict):\n",
    "                outs = item.get(\"outcomes\")\n",
    "                norm[i] = {\n",
    "                    \"description\": item.get(\"description\"),\n",
    "                    \"outcomes\": outs if isinstance(outs, list) else ([outs] if outs else []),\n",
    "                }\n",
    "            else:\n",
    "                norm[i] = {\"description\": str(item), \"outcomes\": []}\n",
    "    elif isinstance(levels_obj, dict):\n",
    "        tmp = []\n",
    "        for k, v in levels_obj.items():\n",
    "            m = re.search(r\"(\\d+)\", str(k))\n",
    "            if m: tmp.append((int(m.group(1)), v))\n",
    "        for n, item in sorted(tmp, key=lambda x: x[0]):\n",
    "            if isinstance(item, dict):\n",
    "                outs = item.get(\"outcomes\")\n",
    "                norm[n] = {\n",
    "                    \"description\": item.get(\"description\"),\n",
    "                    \"outcomes\": outs if isinstance(outs, list) else ([outs] if outs else []),\n",
    "                }\n",
    "            else:\n",
    "                norm[n] = {\"description\": str(item), \"outcomes\": []}\n",
    "    return norm\n",
    "\n",
    "def build_skills_index_from_curriculum(curr_path: Path):\n",
    "    with curr_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        cur = json.load(f)\n",
    "    idx = {}\n",
    "    def walk(o, subject=None, grade=None):\n",
    "        if isinstance(o, dict):\n",
    "            subject = o.get(\"subject\") or subject\n",
    "            grade   = o.get(\"year\") or o.get(\"grade\") or grade\n",
    "            if isinstance(o.get(\"id\"), str) and isinstance(o.get(\"title\"), str):\n",
    "                idx[o[\"id\"]] = {\n",
    "                    \"title\": o[\"title\"],\n",
    "                    \"subject\": subject,\n",
    "                    \"grade\": grade,\n",
    "                    \"levels\": normalize_levels(o.get(\"levels\"))\n",
    "                }\n",
    "            for v in o.values(): walk(v, subject, grade)\n",
    "        elif isinstance(o, list):\n",
    "            for x in o: walk(x, subject, grade)\n",
    "    walk(cur)\n",
    "    return idx\n",
    "\n",
    "if SRC_SKILLS.exists():\n",
    "    skills_index = json.loads(SRC_SKILLS.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    assert SRC_CURR.exists(), \"缺少 skills_index.json 且找不到课程源 JSON 兜底。\"\n",
    "    skills_index = build_skills_index_from_curriculum(SRC_CURR)\n",
    "    SRC_SKILLS.write_text(json.dumps(skills_index, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"ℹ️ 已从 {SRC_CURR.name} 生成临时 skills_index.json（{len(skills_index)} 节点）\")\n",
    "\n",
    "node_exists = set(skills_index.keys())\n",
    "\n",
    "#前缀规范化 \n",
    "PREFIX_MAP = {\"BIOLOGICAL\":\"BIO\", \"PHYSICAL\":\"PHYS\", \"CHEMICAL\":\"CHEM\", \"EARTH\":\"EARTH\"}\n",
    "def normalize_id(node_id: str) -> str:\n",
    "    if not isinstance(node_id, str): return node_id\n",
    "    m = re.match(r\"^([A-Z]+)(\\..+)$\", node_id)\n",
    "    if not m: return node_id\n",
    "    pref, rest = m.group(1), m.group(2)\n",
    "    return (PREFIX_MAP.get(pref, pref)) + rest\n",
    "\n",
    "# 加载职业库并处理\n",
    "careers_doc = json.loads(SRC_CAREERS.read_text(encoding=\"utf-8\"))\n",
    "career_list = careers_doc[\"careers\"] if isinstance(careers_doc, dict) and \"careers\" in careers_doc else careers_doc\n",
    "\n",
    "normalized_careers = []\n",
    "dup_merged_total = 0\n",
    "missing_details = []   # [{career_id, missing:[node,...]}]\n",
    "\n",
    "for c in career_list:\n",
    "    c2 = dict(c)\n",
    "    req = c.get(\"required_knowledge\", []) or []\n",
    "\n",
    "    # 合并同一 node：min_level 取最大、weight 相加\n",
    "    merged = {}\n",
    "    for r in req:\n",
    "        nid = normalize_id(r[\"node\"])\n",
    "        ml  = int(r[\"min_level\"])\n",
    "        wt  = float(r[\"weight\"])\n",
    "        if nid not in merged:\n",
    "            merged[nid] = {\"min_level\": ml, \"weight\": wt}\n",
    "        else:\n",
    "            merged[nid][\"min_level\"] = max(merged[nid][\"min_level\"], ml)\n",
    "            merged[nid][\"weight\"] += wt\n",
    "\n",
    "    after_list = [{\"node\": nid, \"min_level\": v[\"min_level\"], \"weight\": v[\"weight\"]}\n",
    "                  for nid, v in merged.items()]\n",
    "    dup_merged_total += (len(req) - len(after_list))\n",
    "    c2[\"required_knowledge\"] = after_list\n",
    "    normalized_careers.append(c2)\n",
    "\n",
    "    # 引用校验\n",
    "    missing = [x[\"node\"] for x in after_list if x[\"node\"] not in node_exists]\n",
    "    if missing:\n",
    "        missing_details.append({\"career_id\": c.get(\"id\"), \"missing\": missing})\n",
    "\n",
    "#  导出 \n",
    "OUT_CAREERS.write_text(json.dumps({\"careers\": normalized_careers}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "lines = []\n",
    "lines.append(\"# Careers 规范化与校验报告\\n\")\n",
    "lines.append(f\"- 职业总数：{len(normalized_careers)}\\n\")\n",
    "lines.append(f\"- 去重合并条数：{dup_merged_total}\\n\")\n",
    "missing_total = sum(len(x[\"missing\"]) for x in missing_details)\n",
    "lines.append(f\"- 引用缺失节点总数：{missing_total}\\n\")\n",
    "if missing_details:\n",
    "    lines.append(\"\\n## 缺失详情（最多展示 30 条）\\n\")\n",
    "    for row in missing_details[:30]:\n",
    "        lines.append(f\"- {row['career_id']}: {', '.join(row['missing'][:10])}\\n\")\n",
    "OUT_REPORT.write_text(\"\".join(lines), encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ 输出完成：\", OUT_CAREERS.name, \"和\", OUT_REPORT.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77377265-5de0-4714-974e-81bb5da1716f",
   "metadata": {},
   "source": [
    "Step 3 — Users (mock_users_progress.json)\n",
    "\n",
    "What\n",
    "Normalize user knowledge node IDs, coerce all level/grade values to non-negative integers, validate node references against the curriculum, and optionally map career_interests titles → IDs.\n",
    "\n",
    "Why\n",
    "\n",
    "If user node IDs don’t match curriculum IDs, lookups will fail during scoring.\n",
    "\n",
    "Non-integer or negative values distort thresholds and ranking logic.\n",
    "\n",
    "Early detection of missing references helps data QA and backfilling.\n",
    "\n",
    "How\n",
    "\n",
    "Use the same prefix map as Step 2 to normalize knowledge keys; merge duplicates (keep the max level).\n",
    "\n",
    "Clamp grade into [3, 10]; convert inquiry_skills and knowledge levels to non-negative integers.\n",
    "\n",
    "If careers_normalized.json is available, try mapping career_interests titles to career IDs (fallback to original string if not found).\n",
    "\n",
    "For each user/node, verify the node exists in skills_index.json; count missing references.\n",
    "\n",
    "Output\n",
    "\n",
    "users_normalized.json — clean user profiles ready for the rules engine\n",
    "\n",
    "users_validation_report.md — stats (grade clamping, numeric fixes, interest mappings, missing references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314c64de-27e3-4964-a2c1-5a6a7451424d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 输出完成： users_normalized.json 和 users_validation_report.md\n"
     ]
    }
   ],
   "source": [
    "# Step 3 — 处理 mock_users_progress.json：前缀规范化 / 数值清洗 / 引用校验\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path.cwd()\n",
    "SRC_USERS   = BASE / \"mock_users_progress.json\"\n",
    "SRC_SKILLS  = BASE / \"skills_index.json\"\n",
    "SRC_CURR    = BASE / \"Skills and Knowledge years 3-10.json\"   # 兜底：若缺 skills_index 就用课程源构建\n",
    "SRC_CAREERS = BASE / \"careers_normalized.json\"                 # 可选：用于把兴趣名称映射为职业ID\n",
    "\n",
    "OUT_USERS   = BASE / \"users_normalized.json\"\n",
    "OUT_REPORT  = BASE / \"users_validation_report.md\"\n",
    "\n",
    "assert SRC_USERS.exists(), f\"未找到 {SRC_USERS}\"\n",
    "\n",
    "def normalize_levels(levels_obj):\n",
    "    norm = {}\n",
    "    if isinstance(levels_obj, list):\n",
    "        for i, item in enumerate(levels_obj, start=1):\n",
    "            if isinstance(item, dict):\n",
    "                outs = item.get(\"outcomes\")\n",
    "                norm[i] = {\n",
    "                    \"description\": item.get(\"description\"),\n",
    "                    \"outcomes\": outs if isinstance(outs, list) else ([outs] if outs else []),\n",
    "                }\n",
    "            else:\n",
    "                norm[i] = {\"description\": str(item), \"outcomes\": []}\n",
    "    elif isinstance(levels_obj, dict):\n",
    "        tmp = []\n",
    "        for k, v in levels_obj.items():\n",
    "            m = re.search(r\"(\\d+)\", str(k))\n",
    "            if m: tmp.append((int(m.group(1)), v))\n",
    "        for n, item in sorted(tmp, key=lambda x: x[0]):\n",
    "            if isinstance(item, dict):\n",
    "                outs = item.get(\"outcomes\")\n",
    "                norm[n] = {\n",
    "                    \"description\": item.get(\"description\"),\n",
    "                    \"outcomes\": outs if isinstance(outs, list) else ([outs] if outs else []),\n",
    "                }\n",
    "            else:\n",
    "                norm[n] = {\"description\": str(item), \"outcomes\": []}\n",
    "    return norm\n",
    "\n",
    "def build_skills_index_from_curriculum(curr_path: Path):\n",
    "    with curr_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        cur = json.load(f)\n",
    "    idx = {}\n",
    "    def walk(o, subject=None, grade=None):\n",
    "        if isinstance(o, dict):\n",
    "            subject = o.get(\"subject\") or subject\n",
    "            grade   = o.get(\"year\") or o.get(\"grade\") or grade\n",
    "            if isinstance(o.get(\"id\"), str) and isinstance(o.get(\"title\"), str):\n",
    "                idx[o[\"id\"]] = {\n",
    "                    \"title\": o[\"title\"],\n",
    "                    \"subject\": subject,\n",
    "                    \"grade\": grade,\n",
    "                    \"levels\": normalize_levels(o.get(\"levels\"))\n",
    "                }\n",
    "            for v in o.values(): walk(v, subject, grade)\n",
    "        elif isinstance(o, list):\n",
    "            for x in o: walk(x, subject, grade)\n",
    "    walk(cur)\n",
    "    return idx\n",
    "\n",
    "if SRC_SKILLS.exists():\n",
    "    skills_index = json.loads(SRC_SKILLS.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    assert SRC_CURR.exists(), \"缺少 skills_index.json 且找不到课程源 JSON 兜底。\"\n",
    "    skills_index = build_skills_index_from_curriculum(SRC_CURR)\n",
    "    SRC_SKILLS.write_text(json.dumps(skills_index, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"ℹ️ 已从 {SRC_CURR.name} 生成临时 skills_index.json（{len(skills_index)} 节点）\")\n",
    "\n",
    "node_exists = set(skills_index.keys())\n",
    "\n",
    "\n",
    "PREFIX_MAP = {\"BIOLOGICAL\":\"BIO\", \"PHYSICAL\":\"PHYS\", \"CHEMICAL\":\"CHEM\", \"EARTH\":\"EARTH\"}\n",
    "def normalize_id(node_id: str) -> str:\n",
    "    if not isinstance(node_id, str): return node_id\n",
    "    m = re.match(r\"^([A-Z]+)(\\..+)$\", node_id)\n",
    "    if not m: return node_id\n",
    "    pref, rest = m.group(1), m.group(2)\n",
    "    return (PREFIX_MAP.get(pref, pref)) + rest\n",
    "\n",
    "career_title_to_id = {}\n",
    "if SRC_CAREERS.exists():\n",
    "    careers_doc = json.loads(SRC_CAREERS.read_text(encoding=\"utf-8\"))\n",
    "    career_list = careers_doc[\"careers\"] if isinstance(careers_doc, dict) and \"careers\" in careers_doc else careers_doc\n",
    "    for c in career_list:\n",
    "        if isinstance(c.get(\"title\"), str) and isinstance(c.get(\"id\"), str):\n",
    "            career_title_to_id[c[\"title\"].strip().lower()] = c[\"id\"]\n",
    "\n",
    "# user lodaing and processing\n",
    "users_doc = json.loads(SRC_USERS.read_text(encoding=\"utf-8\"))\n",
    "user_list = users_doc[\"users\"] if isinstance(users_doc, dict) and \"users\" in users_doc else users_doc\n",
    "\n",
    "normalized_users = []\n",
    "missing_nodes_total = 0\n",
    "out_of_range_grades = 0\n",
    "fixed_values = 0\n",
    "interest_mapped = 0\n",
    "\n",
    "def to_nonneg_int(x, default=0):\n",
    "    global fixed_values\n",
    "    try:\n",
    "        n = int(round(float(x)))\n",
    "        if n < 0: \n",
    "            fixed_values += 1\n",
    "            return 0\n",
    "        return n\n",
    "    except Exception:\n",
    "        fixed_values += 1\n",
    "        return default\n",
    "\n",
    "for u in user_list:\n",
    "    u2 = dict(u)\n",
    "\n",
    "    # 1) grade set to [3,10]\n",
    "    g = to_nonneg_int(u2.get(\"grade\", 0), 0)\n",
    "    if g < 3 or g > 10:\n",
    "        out_of_range_grades += 1\n",
    "        g = min(max(g, 3), 10)\n",
    "    u2[\"grade\"] = g\n",
    "\n",
    "    # 2) inquiry_skills —— take all non-negative integers\n",
    "    skills_inq = u2.get(\"inquiry_skills\", {}) or {}\n",
    "    cleaned_inq = {}\n",
    "    for k, v in skills_inq.items():\n",
    "        cleaned_inq[k] = to_nonneg_int(v, 0)\n",
    "    u2[\"inquiry_skills\"] = cleaned_inq\n",
    "\n",
    "    # 3) knowledge —— Uniform prefix + non-negative integer level; Merge duplicate keys (after normalization)\n",
    "    know = u2.get(\"knowledge\", {}) or {}\n",
    "    cleaned_kn = {}\n",
    "    for k, v in know.items():\n",
    "        nk = normalize_id(k)\n",
    "        lv = to_nonneg_int(v, 0)\n",
    "        cleaned_kn[nk] = max(cleaned_kn.get(nk, 0), lv)\n",
    "    u2[\"knowledge\"] = cleaned_kn\n",
    "\n",
    "    # 4) career_interests\n",
    "    interests = u2.get(\"career_interests\")\n",
    "    if isinstance(interests, list):\n",
    "        mapped = []\n",
    "        for item in interests:\n",
    "            if isinstance(item, str):\n",
    "                s = item.strip()\n",
    "                if s in career_title_to_id.values():\n",
    "                    mapped.append(s)\n",
    "                else:\n",
    "                    cid = career_title_to_id.get(s.lower())\n",
    "                    mapped.append(cid if cid else s)  \n",
    "                    if cid: interest_mapped += 1\n",
    "        u2[\"career_interests\"] = mapped\n",
    "\n",
    "    for nid in list(cleaned_kn.keys()):\n",
    "        if nid not in node_exists:\n",
    "            missing_nodes_total += 1\n",
    "\n",
    "    normalized_users.append(u2)\n",
    "\n",
    "# export \n",
    "OUT_USERS.write_text(json.dumps({\"users\": normalized_users}, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# report \n",
    "lines = []\n",
    "lines.append(\"# Users 规范化与校验报告\\n\")\n",
    "lines.append(f\"- 用户数量：{len(normalized_users)}\\n\")\n",
    "lines.append(f\"- grade 越界并已裁剪：{out_of_range_grades}\\n\")\n",
    "lines.append(f\"- 数值清洗（无法解析/负数被修正）次数：{fixed_values}\\n\")\n",
    "lines.append(f\"- career_interests 名称→ID 映射成功：{interest_mapped}\\n\")\n",
    "lines.append(f\"- knowledge 引用缺失节点（规范化后）总计：{missing_nodes_total}\\n\")s\n",
    "OUT_REPORT.write_text(\"\".join(lines), encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ 输出完成：\", OUT_USERS.name, \"和\", OUT_REPORT.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0a691-1655-4246-b491-fee18c5dfebb",
   "metadata": {},
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ef5e03-8dd3-4882-bc17-56f2ab56f852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing files: None\n",
      "Career missing refs: 0\n",
      "User missing refs: 0\n"
     ]
    }
   ],
   "source": [
    "# Expect: \"Missing files: None\", \"Career missing refs: 0\", \"User missing refs: 0\"\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "needed = [\"skills_index.json\",\"careers_normalized.json\",\"users_normalized.json\"]\n",
    "missing = [p for p in needed if not Path(p).exists()]\n",
    "print(\"Missing files:\", missing or \"None\")\n",
    "\n",
    "skills = set(json.load(open(\"skills_index.json\",\"r\",encoding=\"utf-8\")).keys())\n",
    "careers = json.load(open(\"careers_normalized.json\",\"r\",encoding=\"utf-8\"))[\"careers\"]\n",
    "users = json.load(open(\"users_normalized.json\",\"r\",encoding=\"utf-8\"))[\"users\"]\n",
    "\n",
    "miss_c = [rk[\"node\"] for c in careers for rk in c[\"required_knowledge\"] if rk[\"node\"] not in skills]\n",
    "miss_u = [nid for u in users for nid in u[\"knowledge\"].keys() if nid not in skills]\n",
    "print(\"Career missing refs:\", len(miss_c))\n",
    "print(\"User missing refs:\", len(miss_u))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdd1b2c-2aef-4c53-a85f-afcbd3008ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
